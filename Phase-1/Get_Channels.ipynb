{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Get_Channels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOQEAioBZfvt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_channel(name):\n",
        "  anchor_content = ((((wiki.page(name,auto_suggest=False)).content).replace(' and ',', ').replace('.','. ')))\n",
        "  # print(anchor_content)\n",
        "  selected_channels = []\n",
        "  Channels_table = pd.read_csv(\"/content/drive/My Drive/Datasets/Channels_Upper.csv\")\n",
        "  Channels_list = Channels_table.Channels.to_list()\n",
        "    \n",
        "  for word in Channels_list:\n",
        "    if anchor_content.find(word)!=-1:\n",
        "      selected_channels.append(word)\n",
        "  print(selected_channels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9eB7ftUZyWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_channel(\"Matt Lauer\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmJzE7ytZ0Yi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_channel(\"Ellen-DeGeneres_Colleen-Williams_Amos-Oz_Nancy-O'Dell_Simcha-Jacobovici_Colleen-Williams\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi5-A80BZ3mu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "Channels_table = (pd.read_csv(\"/content/drive/My Drive/Datasets/Channels.csv\"))\n",
        "Channels_list = Channels_table.Channel"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcyVekTvaFDP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "def get_channel(name):\n",
        "  anchor_content = ((((wiki.page(name,auto_suggest=False)).content).replace(' and ',', ').replace('.','. ')))\n",
        "  # print(anchor_content)\n",
        "  Channels_table = pd.read_csv(\"/content/drive/My Drive/Datasets/Channel_Upper.csv\")\n",
        "  Channel_filter = pd.DataFrame(columns=['Channels', 'Networks'])\n",
        "  Networks_list =['FOX','ABC','CBS','NBC','United Paramount Net','Warner Bros.','Pure Independent','PBS','Pax TV','Telemundo']\n",
        "  Network_filter = []\n",
        "\n",
        "  for word in Channels_table.Channels:\n",
        "    if anchor_content.find(word)!=-1:\n",
        "      req_channels= Channels_table[Channels_table[\"Channels\"]==word ]\n",
        "      Channel_filter = Channel_filter.append(req_channels, ignore_index = True)\n",
        "  \n",
        "  for word in Networks_list:\n",
        "    if anchor_content.find(word)!=-1:\n",
        "      Network_filter.append(word)\n",
        "  \n",
        "  print(Network_filter)\n",
        "    \n",
        "  print(Channel_filter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uD30OrZwaHyb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_channel(\"Daryn Kagan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iuk859WaKWJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "1. Ellen-DeGeneres- Not found ,['ABC', 'NBC', 'PBS']\n",
        "2. Colleen-Williams- KCBC_CBS, KNBC_NBC, KPIX_CBS \n",
        "3. Amos-Oz- Not found\n",
        "4. Nancy-O'Dell - WNBC_NBC, ['NBC']\n",
        "5. Simcha-Jacobovici - Not found, ['ABC', 'NBC', 'PBS']\n",
        "6. Colleen-Williams - KCBC_CBS, KNBC_NBC, KPIX_CBS ['CBS', 'NBC']\n",
        "7. Matt Lauer - WNYW_FOX, WNBC_NBC, WCAU_NBC ,['ABC', 'NBC', 'PBS']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_a0caV3daNXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "list_of_sub= os.listdir('/content/drive/My Drive/Datasets/Subtitles')\n",
        "for y in list_of_sub:\n",
        "  x='/content/drive/My Drive/Datasets/Subtitles'+'/'+y\n",
        "  # an = open('/content/drive/My Drive/Datasets/Subtitles/1975-03-30_0000_US_00023767_B0_B47_M4_E10_TM.txt3')\n",
        "  an=open(x)\n",
        "  anchor_content = an.read()\n",
        "  # print(anchor_content)\n",
        "  Channels_table = pd.read_csv(\"/content/drive/My Drive/Datasets/Channel_Upper.csv\")\n",
        "  Channel_filter = pd.DataFrame(columns=['Channels', 'Networks'])\n",
        "  Networks_list =['FOX','ABC','CBS','NBC','CNN','United Paramount Net','Warner Bros.','Pure Independent','PBS','Pax TV','Telemundo']\n",
        "  Network_filter = []\n",
        "\n",
        "  for word in Channels_table.Channels:\n",
        "    if anchor_content.find(word)!=-1:\n",
        "      req_channels= Channels_table[Channels_table[\"Channels\"]==word ]\n",
        "      Channel_filter = Channel_filter.append(req_channels, ignore_index = True)\n",
        "\n",
        "  for word in Networks_list:\n",
        "    if anchor_content.find(word)!=-1:\n",
        "      Network_filter.append(word)\n",
        "\n",
        "\n",
        "  print(x)\n",
        "  print(Network_filter)\n",
        "    \n",
        "  print(Channel_filter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB6HaVFhaT-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is using for list the directory\n",
        "import os\n",
        "os.listdir('/content/drive/My Drive/Datasets/Subtitles')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}