{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Profession .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhvZegURulU9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 290
        },
        "outputId": "89a8b7a6-0035-4fad-b943-b33803c06e44"
      },
      "source": [
        "pip install wikipedia"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wikipedia\n",
            "  Downloading https://files.pythonhosted.org/packages/67/35/25e68fbc99e672127cc6fbb14b8ec1ba3dfef035bf1e4c90f78f24a80b7d/wikipedia-1.4.0.tar.gz\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (4.6.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wikipedia) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.0.0->wikipedia) (3.0.4)\n",
            "Building wheels for collected packages: wikipedia\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wikipedia: filename=wikipedia-1.4.0-cp36-none-any.whl size=11686 sha256=838a1e91987ba38616c87c751e3a8cfc681ec6fd4d317565c5f92ff45fb2bacf\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/2a/18/4e471fd96d12114d16fe4a446d00c3b38fb9efcb744bd31f4a\n",
            "Successfully built wikipedia\n",
            "Installing collected packages: wikipedia\n",
            "Successfully installed wikipedia-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0dhn05_uzqq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pr_WLC8SvDCN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import wikipedia as wiki"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMJMGNslvKIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_wiki_professions(name):\n",
        " anchor_content = (wiki.page(name)).content\n",
        "#  anchor_content = anchor_content.split('is ')[0]\n",
        " \n",
        " if ' and ' in anchor_content:\n",
        "   and_split = anchor_content.split(' and ')\n",
        "   # print(and_split)\n",
        "   if ', ' in and_split[0]:\n",
        "       if ' is a ' in and_split[0]:\n",
        "         is_a_split = and_split[0].split(' is a ')[1].split('. ')[0].split(', ')+ [and_split[1]]\n",
        "        #  print(is_a_split)\n",
        "         final_profession = [anchor_content.lower() for anchor_content in is_a_split]\n",
        "        #  print(final_profession)\n",
        "       elif ' is an ' in and_split[0]:\n",
        "           is_an_split = and_split[0].split(' is an ')[1].split('. ')[0].split(', ')+ [and_split[1]]\n",
        "           print(is_an_split)\n",
        "           final_profession = [anchor_content.lower() for anchor_content in is_an_split]\n",
        "          #  print(final_profession)\n",
        "       elif ' was a ' in and_split[0]:\n",
        "           was_a_split = and_split[0].split(' was a ')[1].split('. ')[0].split(', ')+ [and_split[1]]\n",
        "           print(was_a_split)\n",
        "           final_profession =[anchor_content.lower() for anchor_content in was_a_split]\n",
        "          #  print(final_profession)\n",
        "       elif ' was an ' in and_split[0]:\n",
        "           was_an_split = and_split[0].split(' was an ')[1].split('. ')[0].split(', ')+ [and_split[1]]\n",
        "           print(was_an_split)\n",
        "           final_profession = [anchor_content.lower() for anchor_content in was_an_split]\n",
        "          #  print(final_profession)\n",
        " \n",
        "   else:\n",
        "       if ' is a ' in and_split[0]:\n",
        "         is_a_split = and_split[0].split(' is a ')[1].split(' ')+[and_split[1]]\n",
        "         final_profession = [anchor_content.lower() for anchor_content in is_a_split]\n",
        "        #  print(final_profession)\n",
        "       elif ' is an ' in and_split[0]:\n",
        "         is_an_split = and_split[0].split(' is an ')[1].split(' ')+[and_split[1]]\n",
        "        #  print(is_an_split)\n",
        "         final_profession = [anchor_content.lower() for anchor_content in is_an_split]\n",
        "        #  print(final_profession)\n",
        "       elif ' was a ' in and_split[0]:\n",
        "         was_a_split = and_split[0].split(' was a ')[1].split(' ')+[and_split[1]]\n",
        "         final_profession =[anchor_content.lower() for anchor_content in was_a_split]\n",
        "        #  print(final_profession)\n",
        "       elif ' was an ' in and_split[0]:\n",
        "         was_an_split = and_split[0].split(' was an ')[1].split(' ')+[and_split[1]]\n",
        "         final_profession = [anchor_content.lower() for anchor_content in was_an_split]\n",
        "        #  print(final_profession)     \n",
        " else:\n",
        "   if ' is a ' in anchor_content:\n",
        "     is_a_split = anchor_content.split(' is a ')[1].split('. ')[0].split(', ')\n",
        "     final_profession = [anchor_content.lower() for anchor_content in is_a_split]\n",
        "    #  print(final_profession)\n",
        " \n",
        "   elif ' is an ' in anchor_content:\n",
        "     is_an_split = anchor_content.split(' is an ')[1].split('. ')[0].split(', ')\n",
        "     final_profession = [anchor_content.lower() for anchor_content in is_an_split]\n",
        "    #  print(final_profession)\n",
        " \n",
        "   elif ' was a ' in anchor_content:\n",
        "     was_a_split = anchor_content.split(' was a ')[1].split('. ')[0].split(', ')\n",
        "     final_profession = [anchor_content.lower() for anchor_content in was_a_split]\n",
        "    #  print(final_profession)\n",
        " \n",
        "   elif ' was an ' in anchor_content:\n",
        "       was_an_split = anchor_content.split(' was an ')[1].split('. ')[0].split(', ')\n",
        "       final_profession = [anchor_content.lower() for anchor_content in was_an_split]\n",
        "      #  print(final_profession)   \n",
        " \n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1F7vtAVbPijq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "26a15feb-5877-4e86-a6ff-0fd5fe47b146"
      },
      "source": [
        " x = check_profession(\"Bob-Bergen\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['American', 'voice', 'actor.', 'He', 'is', 'the', 'current', 'voice', 'of', 'the', 'Warner', 'Bros.', 'cartoon', 'character', 'Porky', 'Pig', \"formerly hosted Jep!, a kids' version of the popular game show Jeopardy!. He is also known for voicing characters in the English dubs of various anime.\\n\\n\\n== Life\"]\n",
            "['american', 'voice', 'actor.', 'he', 'is', 'the', 'current', 'voice', 'of', 'the', 'warner', 'bros.', 'cartoon', 'character', 'porky', 'pig', \"formerly hosted jep!, a kids' version of the popular game show jeopardy!. he is also known for voicing characters in the english dubs of various anime.\\n\\n\\n== life\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFCbX6skDXIa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "cfe1db5a-ef1f-4500-e777-7aa8849ece0f"
      },
      "source": [
        "for word in ['host','presenter','journalist','news anchor','correspondent','anchor']:\n",
        "  if word in x:\n",
        "    answer = True\n",
        "    break\n",
        "  else:\n",
        "    answer = False\n",
        "answer"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-c27a4dcf1542>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'host'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'presenter'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'journalist'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'news anchor'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'correspondent'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'anchor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixzmkKoxPYti",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}